{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Loading data\n",
    "\n",
    "The following code shows how to load the datasets for this project.  \n",
    "Among which, we do not release the labels (the \"stars\" column) for the test set. \n",
    "You may evaluate your trained model on the validation set instead.\n",
    "However, your submitted predictions (``pred.csv``) should be generated on the test set.\n",
    "\n",
    "Each year we release different data, so old models are not guaranteed to solve the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split_name='train', columns=['text', 'stars'], folder='data'):\n",
    "    '''\n",
    "        \"split_name\" may be set as 'train', 'valid' or 'test' to load the corresponding dataset.\n",
    "        \n",
    "        You may also specify the column names to load any columns in the .csv data file.\n",
    "        Among many, \"text\" can be used as model input, and \"stars\" column is the labels (sentiment). \n",
    "        If you like, you are free to use columns other than \"text\" for prediction.\n",
    "    '''\n",
    "    try:\n",
    "        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        df = df.loc[:,columns]\n",
    "        print(\"Success\")\n",
    "        return df\n",
    "    except:\n",
    "        print(f\"Failed loading specified columns... Returning all columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can extract the data by specifying the desired split and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, stars, cool, funny, useful] columns from the train split\n",
      "Success\n",
      "select [text, stars, cool, funny, useful] columns from the valid split\n",
      "Success\n",
      "select [text, stars] columns from the test split\n",
      "Failed loading specified columns... Returning all columns from the test split\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train', columns=['text', 'stars','cool','funny','useful'], folder='data')\n",
    "valid_df = load_data('valid', columns=['text', 'stars','cool','funny','useful'], folder='data')\n",
    "# the test set labels (the 'stars' column) are not available! So the following code will instead return all columns\n",
    "test_df = load_data('test', columns=['text', 'stars'], folder='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RobertA\n",
    "\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 20:23:55.811335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/lib64\n",
      "2022-03-29 20:23:55.811373: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.model_max_len=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize dataset\n",
    "def tokenize(text):\n",
    "  return tokenizer(text, truncation=True,max_length=512,padding='max_length')\n",
    "\n",
    "def tokenize_df(df):\n",
    "  tokens = df['text'].map(tokenize)\n",
    "  df['input_ids'] = [x['input_ids'] for x in tokens]\n",
    "  df['attention_mask'] = [x['attention_mask'] for x in tokens]\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tokenize_df(train_df)\n",
    "valid_df = tokenize_df(valid_df)\n",
    "test_df = tokenize_df(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "learning_rate = 1e-5\n",
    "dropout_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "  def __init__(self,checkpoint,num_labels): \n",
    "    super(CustomModel,self).__init__() \n",
    "    self.num_labels = num_labels \n",
    "\n",
    "    #Load Model with given checkpoint and extract its body\n",
    "    self.model = AutoModel.from_pretrained(checkpoint,config=AutoConfig.from_pretrained(checkpoint, output_attentions=True,output_hidden_states=True))\n",
    "    self.dropout = nn.Dropout(dropout_prob) \n",
    "    self.classifier = nn.Linear(771,num_labels) # load and initialize weights\n",
    "\n",
    "\n",
    "  def forward(self, input_ids=None, attention_mask=None, reactions=None, labels=None):\n",
    "    #Extract outputs from the body\n",
    "    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    #Add custom layers\n",
    "    sequence_output = self.dropout(outputs[0]) #outputs[0]=last hidden state\n",
    "\n",
    "    #Concat sequence_output with reactions (,3)\n",
    "    output_concat = torch.cat((sequence_output[:,0,:].view(-1,768), reactions),dim=1)\n",
    "\n",
    "    logits = self.classifier(output_concat) \n",
    "    \n",
    "    # calculate losses\n",
    "    loss = None\n",
    "    if labels is not None:\n",
    "      loss_fct = nn.CrossEntropyLoss()\n",
    "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "    \n",
    "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-emotion were not used when initializing RobertaModel: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=CustomModel(checkpoint=checkpoint,num_labels=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        assert len(df['input_ids']) == len(df['stars'])\n",
    "        self.input_ids = df['input_ids']\n",
    "        self.attention_mask = df['attention_mask']\n",
    "        self.label = df['stars']-1\n",
    "        self.reactions = df[['cool','funny','useful']].values\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return np.asarray(self.input_ids[idx]), np.asarray(self.attention_mask[idx]), self.reactions[idx] ,self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(MyDataset(train_df), batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(MyDataset(valid_df), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mohaa/miniconda3/envs/comp4332/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW,get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [11:57<00:00,  3.14it/s, train_loss=0.097, train_acc=0.671] \n",
      "100%|██████████| 250/250 [00:26<00:00,  9.59it/s, val_loss=0.0841, val_acc=0.716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       282\n",
      "           1       0.53      0.40      0.46       136\n",
      "           2       0.52      0.66      0.58       212\n",
      "           3       0.58      0.44      0.50       466\n",
      "           4       0.80      0.87      0.83       904\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.65      0.64      2000\n",
      "weighted avg       0.71      0.72      0.71      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[248  24  10   0   0]\n",
      " [ 36  54  44   2   0]\n",
      " [  8  17 139  42   6]\n",
      " [  4   3  67 203 189]\n",
      " [  4   3   9 101 787]]\n",
      "epoch  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [11:40<00:00,  3.21it/s, train_loss=0.0788, train_acc=0.733]\n",
      "100%|██████████| 250/250 [00:26<00:00,  9.59it/s, val_loss=0.0834, val_acc=0.719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       282\n",
      "           1       0.46      0.39      0.42       136\n",
      "           2       0.55      0.60      0.57       212\n",
      "           3       0.59      0.50      0.54       466\n",
      "           4       0.81      0.87      0.84       904\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.64      0.64      2000\n",
      "weighted avg       0.71      0.72      0.71      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[237  37   8   0   0]\n",
      " [ 33  53  48   2   0]\n",
      " [  3  22 128  54   5]\n",
      " [  3   1  45 235 182]\n",
      " [  3   2   5 110 784]]\n",
      "epoch  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [11:58<00:00,  3.13it/s, train_loss=0.0662, train_acc=0.782]\n",
      "100%|██████████| 250/250 [00:26<00:00,  9.57it/s, val_loss=0.0862, val_acc=0.72] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83       282\n",
      "           1       0.44      0.46      0.45       136\n",
      "           2       0.54      0.62      0.58       212\n",
      "           3       0.60      0.51      0.55       466\n",
      "           4       0.82      0.87      0.84       904\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.65      0.65      2000\n",
      "weighted avg       0.72      0.72      0.72      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[224  51   7   0   0]\n",
      " [ 25  63  47   1   0]\n",
      " [  2  23 131  52   4]\n",
      " [  3   2  50 238 173]\n",
      " [  4   3   7 106 784]]\n",
      "epoch  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [12:02<00:00,  3.11it/s, train_loss=0.0549, train_acc=0.823]\n",
      "100%|██████████| 250/250 [00:26<00:00,  9.60it/s, val_loss=0.0951, val_acc=0.72] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       282\n",
      "           1       0.49      0.38      0.43       136\n",
      "           2       0.55      0.54      0.54       212\n",
      "           3       0.58      0.53      0.56       466\n",
      "           4       0.81      0.86      0.84       904\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.64      0.64      2000\n",
      "weighted avg       0.71      0.72      0.71      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[249  27   6   0   0]\n",
      " [ 42  52  41   1   0]\n",
      " [  6  24 114  63   5]\n",
      " [  4   1  42 247 172]\n",
      " [  4   3   6 113 778]]\n",
      "epoch  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2250/2250 [11:58<00:00,  3.13it/s, train_loss=0.046, train_acc=0.857] \n",
      "100%|██████████| 250/250 [00:26<00:00,  9.56it/s, val_loss=0.103, val_acc=0.721]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       282\n",
      "           1       0.47      0.43      0.45       136\n",
      "           2       0.55      0.51      0.53       212\n",
      "           3       0.58      0.53      0.56       466\n",
      "           4       0.82      0.87      0.84       904\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.64      0.65      2000\n",
      "weighted avg       0.71      0.72      0.72      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[244  33   5   0   0]\n",
      " [ 39  59  36   2   0]\n",
      " [  3  31 108  66   4]\n",
      " [  4   0  41 248 173]\n",
      " [  4   3   5 109 783]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):    \n",
    "    print('epoch ', epoch)\n",
    "    model.train()\n",
    "    train_acc = 0\n",
    "    train_loss = 0\n",
    "    train_count = 0\n",
    "    with tqdm.tqdm(train_dataloader) as t:\n",
    "        for input_ids, attention_mask, reactions, labels in t:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            reactions = reactions.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids,attention_mask,reactions,labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            train_acc += (torch.argmax(outputs.logits,dim=-1) == labels).sum().item()\n",
    "            train_count += labels.size(0)\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            t.set_postfix({'train_loss': train_loss/train_count, 'train_acc': train_acc/train_count})\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    val_acc = 0\n",
    "    val_count = 0\n",
    "    val_loss = 0\n",
    "    with tqdm.tqdm(valid_dataloader) as t:\n",
    "        for input_ids, attention_mask, reactions, labels in t:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            reactions = reactions.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids,attention_mask,reactions,labels)\n",
    "                loss = outputs.loss\n",
    "            val_acc += (torch.argmax(outputs.logits,dim=-1) == labels).sum().item()\n",
    "            val_count += len(labels)\n",
    "            val_loss += loss.item()\n",
    "            y_pred += torch.argmax(outputs.logits,dim=-1).tolist()\n",
    "            y_true += labels.tolist()\n",
    "\n",
    "            t.set_postfix({'val_loss': val_loss/val_count, 'val_acc': val_acc/val_count})\n",
    "    \n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\n\\n\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    # torch.save(model.state_dict(), 'checkpoints/model_bs{}_lr{}_dop{}_e{}.pth'.format(batch_size, learning_rate, dropout_prob, epoch+3))\n",
    "    # with open('logs/model_bs{}_lr{}_dop{}_e{}.txt'.format(batch_size, learning_rate, dropout_prob, epoch), 'w') as f:\n",
    "    #     f.write(str(classification_report(y_true, y_pred)))\n",
    "    #     f.write(\"\\n\\n\")\n",
    "    #     f.write(str(confusion_matrix(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoints/model_bs{}_lr{}_dop{}.pth'.format(batch_size, learning_rate, dropout_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('model1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:25<00:00,  9.88it/s, val_loss=0.103, val_acc=0.721]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "val_acc = 0\n",
    "val_count = 0\n",
    "val_loss = 0\n",
    "with tqdm.tqdm(valid_dataloader) as t:\n",
    "    for input_ids, attention_mask, reactions, labels in t:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        reactions = reactions.to(device)\n",
    "        labels = labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids,attention_mask,reactions,labels)\n",
    "            loss = outputs.loss\n",
    "        val_acc += (torch.argmax(outputs.logits,dim=-1) == labels).sum().item()\n",
    "        val_count += len(labels)\n",
    "        val_loss += loss.item()\n",
    "        y_pred += torch.argmax(outputs.logits,dim=-1).tolist()\n",
    "        y_true += labels.tolist()\n",
    "\n",
    "        t.set_postfix({'val_loss': val_loss/val_count, 'val_acc': val_acc/val_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logs/model_bs{}_lr{}_dop{}_outputcat.txt'.format(batch_size, learning_rate, dropout_prob), 'w') as f:\n",
    "    f.write(str(classification_report(y_true, y_pred)))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(str(confusion_matrix(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Saving predictions to file\n",
    "\n",
    "Your submitted predictions are supposed to be a .csv file containing two columns, i.e. (``review_id`` and ``stars``). \n",
    "\n",
    "Here, as an example, we generate some random predictions as our answer, which are put in a DataFrame and output to a .csv file\n",
    "\n",
    "After getting your model predictions on the test set, you may follow these steps to generate your ``pred.csv`` file. (By replacing the random predictions with your model predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        assert len(df['input_ids']) == len(df['attention_mask'])\n",
    "        self.input_ids = df['input_ids']\n",
    "        self.attention_mask = df['attention_mask']\n",
    "        self.reactions = df[['cool','funny','useful']].values\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return np.asarray(self.input_ids[idx]), np.asarray(self.attention_mask[idx]), self.reactions[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "test_dataloader = DataLoader(MyTestDataset(test_df), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:51<00:00,  9.75it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = []\n",
    "with tqdm.tqdm(test_dataloader) as t:\n",
    "    for input_ids, attention_mask, reactions in t:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        reactions = reactions.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids,attention_mask,reactions)\n",
    "        y_pred += torch.argmax(outputs.logits,dim=-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['stars'] = [x+1 for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IKcZpSuELli7DUjU2fKGNg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-04-07 17:17:39</td>\n",
       "      <td>0</td>\n",
       "      <td>I77zZlSdCFAClxdjHwPcxw</td>\n",
       "      <td>OMG! I'm an avid spray tanner and have been al...</td>\n",
       "      <td>2</td>\n",
       "      <td>tUZtqzqE0bIOcLelcR4opg</td>\n",
       "      <td>[0, 3765, 534, 328, 38, 437, 41, 20137, 11782,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vbVJzKDhHlhMnKRpES5QzQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-30 17:42:40</td>\n",
       "      <td>0</td>\n",
       "      <td>ioFNKarf29KGjRZdH0qC8Q</td>\n",
       "      <td>Sets the standard. Authentic. Outstanding. Cou...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gwvrebru-kDM1N51aeJiFg</td>\n",
       "      <td>[0, 104, 2580, 5, 2526, 4, 41808, 636, 4, 2548...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GdPWJo3z4ySEXpF7Wkn3FA</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-08-02 05:53:47</td>\n",
       "      <td>2</td>\n",
       "      <td>9429anmcYIcaEcMptJCNKQ</td>\n",
       "      <td>Came on 7/23/2014 with a group of 10 - service...</td>\n",
       "      <td>1</td>\n",
       "      <td>at7dS8gtLiEwd_4uHv231A</td>\n",
       "      <td>[0, 347, 4344, 15, 262, 73, 1922, 73, 16310, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BYc5IFQPq-PLVXnYjDp6vw</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-20 19:31:21</td>\n",
       "      <td>0</td>\n",
       "      <td>PsUCdt7PKjzgBC0c7xXhJA</td>\n",
       "      <td>I love Bobs Subs! Tasty n made to order...yum!...</td>\n",
       "      <td>0</td>\n",
       "      <td>vaQxpV8IXqRmCIAHovP4NA</td>\n",
       "      <td>[0, 100, 657, 3045, 29, 4052, 29, 328, 255, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wxxvi3LZbHNIDwJ-ZimtnA</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-06-27 00:44:08</td>\n",
       "      <td>0</td>\n",
       "      <td>GQBlykKyShQcNeu2ivLdSA</td>\n",
       "      <td>This is my hotel of choice on the strip.  I re...</td>\n",
       "      <td>0</td>\n",
       "      <td>dy_4NAZ0KR2bDoB9qAOMRg</td>\n",
       "      <td>[0, 713, 16, 127, 2303, 9, 2031, 15, 5, 9572, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                 date  funny  \\\n",
       "0  IKcZpSuELli7DUjU2fKGNg     1  2015-04-07 17:17:39      0   \n",
       "1  vbVJzKDhHlhMnKRpES5QzQ     1  2017-06-30 17:42:40      0   \n",
       "2  GdPWJo3z4ySEXpF7Wkn3FA     0  2014-08-02 05:53:47      2   \n",
       "3  BYc5IFQPq-PLVXnYjDp6vw     0  2015-02-20 19:31:21      0   \n",
       "4  Wxxvi3LZbHNIDwJ-ZimtnA     0  2012-06-27 00:44:08      0   \n",
       "\n",
       "                review_id                                               text  \\\n",
       "0  I77zZlSdCFAClxdjHwPcxw  OMG! I'm an avid spray tanner and have been al...   \n",
       "1  ioFNKarf29KGjRZdH0qC8Q  Sets the standard. Authentic. Outstanding. Cou...   \n",
       "2  9429anmcYIcaEcMptJCNKQ  Came on 7/23/2014 with a group of 10 - service...   \n",
       "3  PsUCdt7PKjzgBC0c7xXhJA  I love Bobs Subs! Tasty n made to order...yum!...   \n",
       "4  GQBlykKyShQcNeu2ivLdSA  This is my hotel of choice on the strip.  I re...   \n",
       "\n",
       "   useful                 user_id  \\\n",
       "0       2  tUZtqzqE0bIOcLelcR4opg   \n",
       "1       1  Gwvrebru-kDM1N51aeJiFg   \n",
       "2       1  at7dS8gtLiEwd_4uHv231A   \n",
       "3       0  vaQxpV8IXqRmCIAHovP4NA   \n",
       "4       0  dy_4NAZ0KR2bDoB9qAOMRg   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [0, 3765, 534, 328, 38, 437, 41, 20137, 11782,...   \n",
       "1  [0, 104, 2580, 5, 2526, 4, 41808, 636, 4, 2548...   \n",
       "2  [0, 347, 4344, 15, 262, 73, 1922, 73, 16310, 1...   \n",
       "3  [0, 100, 657, 3045, 29, 4052, 29, 328, 255, 19...   \n",
       "4  [0, 713, 16, 127, 2303, 9, 2031, 15, 5, 9572, ...   \n",
       "\n",
       "                                      attention_mask  stars  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      5  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      5  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      5  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(f'test_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(data={\n",
    "    'review_id': test_df['review_id'],\n",
    "    'stars': test_df['stars']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I77zZlSdCFAClxdjHwPcxw</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ioFNKarf29KGjRZdH0qC8Q</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9429anmcYIcaEcMptJCNKQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PsUCdt7PKjzgBC0c7xXhJA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GQBlykKyShQcNeu2ivLdSA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  stars\n",
       "0  I77zZlSdCFAClxdjHwPcxw      5\n",
       "1  ioFNKarf29KGjRZdH0qC8Q      5\n",
       "2  9429anmcYIcaEcMptJCNKQ      1\n",
       "3  PsUCdt7PKjzgBC0c7xXhJA      5\n",
       "4  GQBlykKyShQcNeu2ivLdSA      4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(f'pred_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
