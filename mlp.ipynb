{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /data/jkimbf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split_name='train', columns=['text', 'stars'], folder='data'):\n",
    "    '''\n",
    "        \"split_name\" may be set as 'train', 'valid' or 'test' to load the corresponding dataset.\n",
    "        \n",
    "        You may also specify the column names to load any columns in the .csv data file.\n",
    "        Among many, \"text\" can be used as model input, and \"stars\" column is the labels (sentiment). \n",
    "        If you like, you are free to use columns other than \"text\" for prediction.\n",
    "    '''\n",
    "    try:\n",
    "        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        df = df.loc[:,columns]\n",
    "        print(\"Success\")\n",
    "        return df\n",
    "    except:\n",
    "        print(f\"Failed loading specified columns... Returning all columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, stars] columns from the train split\n",
      "Success\n",
      "select [text, stars] columns from the valid split\n",
      "Success\n",
      "select [text, stars] columns from the test split\n",
      "Failed loading specified columns... Returning all columns from the test split\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df, test_df = [\n",
    "    load_data(x, columns=['text', 'stars'], folder='data') for x in ['train', 'valid', 'test']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've been here a handful of times now and I've...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The service was terrible. The food was just ok...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alil pricey for the location but completly get...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don't get your car washed here. Paid 11 and my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cute but tight. Not expensive and creative. I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  I've been here a handful of times now and I've...      5\n",
       "1  The service was terrible. The food was just ok...      1\n",
       "2  Alil pricey for the location but completly get...      4\n",
       "3  Don't get your car washed here. Paid 11 and my...      1\n",
       "4  Cute but tight. Not expensive and creative. I ...      5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000 2000 4000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(valid_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def lower(s):\n",
    "    \"\"\"\n",
    "    :param s: a string.\n",
    "    return a string with lower characters\n",
    "    Note that we allow the input to be nested string of a list.\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: 'text mining is to identify useful information.'\n",
    "    \"\"\"\n",
    "    if isinstance(s, list):\n",
    "        return [lower(t) for t in s]\n",
    "    if isinstance(s, str):\n",
    "        return s.lower()\n",
    "    else:\n",
    "        raise NotImplementedError(\"unknown datatype\")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    :param text: a doc with multiple sentences, type: str\n",
    "    return a word list, type: list\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "def stem(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of stemmed words, type: list\n",
    "    e.g.\n",
    "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    ### equivalent code\n",
    "    # results = list()\n",
    "    # for token in tokens:\n",
    "    #     results.append(ps.stem(token))\n",
    "    # return results\n",
    "\n",
    "    return [ps.stem(token) for token in tokens]\n",
    "\n",
    "def n_gram(tokens, n=1):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    :param n: the corresponding n-gram, type: int\n",
    "    return a list of n-gram tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.'], 2\n",
    "    Output: ['text mine', 'mine is', 'is to', 'to identifi', 'identifi use', 'use inform', 'inform .']\n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return tokens\n",
    "    else:\n",
    "        results = list()\n",
    "        for i in range(len(tokens)-n+1):\n",
    "            # tokens[i:i+n] will return a sublist from i th to i+n th (i+n th is not included)\n",
    "            results.append(\" \".join(tokens[i:i+n]))\n",
    "        return results\n",
    "\n",
    "def filter_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of filtered tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    ### equivalent code\n",
    "    # results = list()\n",
    "    # for token in tokens:\n",
    "    #     if token not in stopwords and not token.isnumeric():\n",
    "    #         results.append(token)\n",
    "    # return results\n",
    "\n",
    "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_onehot_vector(feats, feats_dict):\n",
    "    \"\"\"\n",
    "    :param data: a list of features, type: list\n",
    "    :param feats_dict: a dict from features to indices, type: dict\n",
    "    return a feature vector,\n",
    "    \"\"\"\n",
    "    # initialize the vector as all zeros\n",
    "    vector = np.zeros(len(feats_dict), dtype=np.float)\n",
    "    for f in feats:\n",
    "        # get the feature index, return -1 if the feature is not existed\n",
    "        f_idx = feats_dict.get(f, -1)\n",
    "        if f_idx != -1:\n",
    "            # set the corresponding element as 1\n",
    "            vector[f_idx] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tokens'] = train_df['text'].map(tokenize).map(filter_stopwords).map(lower)\n",
    "valid_df['tokens'] = valid_df['text'].map(tokenize).map(filter_stopwords).map(lower)\n",
    "test_df['tokens'] = test_df['text'].map(tokenize).map(filter_stopwords).map(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict = {}\n",
    "with open('glove.twitter.27B.200d.txt', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        values = line.split()\n",
    "        if i == 38522: continue # ' ' token not used\n",
    "        glove_dict[values[0]] = np.asarray(values[1:], 'float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Averaged embedding for <UNK> token \"\"\"\n",
    "glove_dict['<UNK>'] = np.mean(list(glove_dict.values()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_avg_emb(texts):\n",
    "    records = []\n",
    "    for tokens in texts:\n",
    "        record = [\n",
    "            glove_dict[token] if token in glove_dict.keys() else glove_dict['<UNK>'] for token in tokens\n",
    "        ]\n",
    "        records.append(np.mean(record, axis=0))\n",
    "    return np.asarray(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = tokens_to_avg_emb(train_df['tokens'])\n",
    "valid_x = tokens_to_avg_emb(valid_df['tokens'])\n",
    "train_y = train_df['stars']\n",
    "valid_y = valid_df['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seq, y):\n",
    "        assert len(seq) == len(y)\n",
    "        self.seq = seq\n",
    "        self.y = y-1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return np.asarray(self.seq[idx]), self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(MyDataset(train_x, train_y), batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(MyDataset(valid_x, valid_y), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(200, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:05<00:00, 212.53it/s, loss=0.0777, acc=0.495]\n",
      "100%|██████████| 125/125 [00:00<00:00, 1303.17it/s]\n",
      "/data/jkimbf/miniconda3/envs/comp4471/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/jkimbf/miniconda3/envs/comp4471/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/jkimbf/miniconda3/envs/comp4471/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.85      0.59       282\n",
      "           1       0.00      0.00      0.00       136\n",
      "           2       0.00      0.00      0.00       212\n",
      "           3       0.40      0.38      0.39       466\n",
      "           4       0.70      0.80      0.74       904\n",
      "\n",
      "    accuracy                           0.57      2000\n",
      "   macro avg       0.31      0.41      0.35      2000\n",
      "weighted avg       0.47      0.57      0.51      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[241   0   1  11  29]\n",
      " [ 94   0   2  29  11]\n",
      " [ 80   0   0  90  42]\n",
      " [ 59   0   1 175 231]\n",
      " [ 55   0   0 128 721]]\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:05<00:00, 209.54it/s, loss=0.0634, acc=0.577]\n",
      "100%|██████████| 125/125 [00:00<00:00, 1030.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.89      0.65       282\n",
      "           1       0.14      0.02      0.04       136\n",
      "           2       0.32      0.19      0.24       212\n",
      "           3       0.47      0.43      0.45       466\n",
      "           4       0.76      0.79      0.77       904\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.44      0.46      0.43      2000\n",
      "weighted avg       0.57      0.60      0.57      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[250   2   8   4  18]\n",
      " [ 90   3  19  20   4]\n",
      " [ 62  11  41  68  30]\n",
      " [ 41   4  44 200 177]\n",
      " [ 41   1  18 134 710]]\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:05<00:00, 215.87it/s, loss=0.0607, acc=0.596]\n",
      "100%|██████████| 125/125 [00:00<00:00, 1574.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69       282\n",
      "           1       0.29      0.04      0.07       136\n",
      "           2       0.40      0.24      0.30       212\n",
      "           3       0.46      0.53      0.49       466\n",
      "           4       0.77      0.77      0.77       904\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.50      0.48      0.46      2000\n",
      "weighted avg       0.60      0.62      0.59      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[239   3  11   7  22]\n",
      " [ 78   5  24  27   2]\n",
      " [ 41   6  50  87  28]\n",
      " [ 28   2  31 247 158]\n",
      " [ 28   1   9 173 693]]\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:05<00:00, 221.96it/s, loss=0.0593, acc=0.61] \n",
      "100%|██████████| 125/125 [00:00<00:00, 1571.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.71       282\n",
      "           1       0.29      0.10      0.15       136\n",
      "           2       0.39      0.25      0.31       212\n",
      "           3       0.46      0.40      0.43       466\n",
      "           4       0.73      0.82      0.77       904\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.50      0.49      0.47      2000\n",
      "weighted avg       0.58      0.62      0.59      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[239   5  10   5  23]\n",
      " [ 73  14  23  22   4]\n",
      " [ 28  23  54  72  35]\n",
      " [ 24   4  41 188 209]\n",
      " [ 24   3  10 126 741]]\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:05<00:00, 207.80it/s, loss=0.0585, acc=0.615]\n",
      "100%|██████████| 125/125 [00:00<00:00, 1275.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73       282\n",
      "           1       0.29      0.13      0.18       136\n",
      "           2       0.39      0.31      0.34       212\n",
      "           3       0.47      0.40      0.43       466\n",
      "           4       0.74      0.82      0.78       904\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.51      0.50      0.49      2000\n",
      "weighted avg       0.60      0.62      0.60      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[239   7  10   5  21]\n",
      " [ 69  18  27  17   5]\n",
      " [ 24  25  65  66  32]\n",
      " [ 22   8  45 187 204]\n",
      " [ 21   4  18 121 740]]\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:05<00:00, 208.84it/s, loss=0.0579, acc=0.614]\n",
      "100%|██████████| 125/125 [00:00<00:00, 1524.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.86      0.73       282\n",
      "           1       0.26      0.14      0.18       136\n",
      "           2       0.33      0.31      0.32       212\n",
      "           3       0.47      0.38      0.42       466\n",
      "           4       0.75      0.81      0.78       904\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.49      0.50      0.48      2000\n",
      "weighted avg       0.59      0.62      0.60      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[243   8   8   4  19]\n",
      " [ 70  19  30  14   3]\n",
      " [ 27  30  65  62  28]\n",
      " [ 25  10  67 175 189]\n",
      " [ 22   6  26 119 731]]\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:05<00:00, 218.04it/s, loss=0.0576, acc=0.617]\n",
      "100%|██████████| 125/125 [00:00<00:00, 1498.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       282\n",
      "           1       0.33      0.15      0.20       136\n",
      "           2       0.40      0.31      0.35       212\n",
      "           3       0.47      0.45      0.46       466\n",
      "           4       0.73      0.83      0.78       904\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.52      0.50      0.50      2000\n",
      "weighted avg       0.60      0.63      0.61      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[210  16  16   6  34]\n",
      " [ 55  20  32  22   7]\n",
      " [ 16  16  65  80  35]\n",
      " [ 12   7  38 212 197]\n",
      " [  9   2  12 133 748]]\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:05<00:00, 215.50it/s, loss=0.0572, acc=0.623]\n",
      "100%|██████████| 125/125 [00:00<00:00, 1304.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.83      0.74       282\n",
      "           1       0.36      0.18      0.24       136\n",
      "           2       0.38      0.32      0.35       212\n",
      "           3       0.49      0.49      0.49       466\n",
      "           4       0.77      0.79      0.78       904\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.53      0.52      0.52      2000\n",
      "weighted avg       0.62      0.63      0.62      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[233  11  13   6  19]\n",
      " [ 59  25  30  17   5]\n",
      " [ 22  25  67  72  26]\n",
      " [ 17   7  46 227 169]\n",
      " [ 21   2  19 146 716]]\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:05<00:00, 207.25it/s, loss=0.0568, acc=0.621]\n",
      "100%|██████████| 125/125 [00:00<00:00, 1072.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       282\n",
      "           1       0.27      0.11      0.16       136\n",
      "           2       0.37      0.25      0.30       212\n",
      "           3       0.49      0.38      0.43       466\n",
      "           4       0.73      0.85      0.79       904\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.50      0.49      0.48      2000\n",
      "weighted avg       0.59      0.63      0.60      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[245   6   8   4  19]\n",
      " [ 73  15  26  16   6]\n",
      " [ 35  22  52  66  37]\n",
      " [ 23  11  37 177 218]\n",
      " [ 23   2  16  95 768]]\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:05<00:00, 208.39it/s, loss=0.0564, acc=0.625]\n",
      "100%|██████████| 125/125 [00:00<00:00, 1116.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.82      0.73       282\n",
      "           1       0.38      0.15      0.21       136\n",
      "           2       0.43      0.26      0.33       212\n",
      "           3       0.48      0.39      0.43       466\n",
      "           4       0.71      0.86      0.78       904\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.53      0.50      0.50      2000\n",
      "weighted avg       0.60      0.63      0.60      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[232   5  10   5  30]\n",
      " [ 65  20  25  16  10]\n",
      " [ 26  18  56  69  43]\n",
      " [ 15   9  31 183 228]\n",
      " [ 15   0   9 106 774]]\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "num_epochs = 10\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    print('epoch', e+1)\n",
    "    model.train()\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    with tqdm.tqdm(train_loader) as t:\n",
    "        for x, y in t:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            total_acc += (logits.argmax(1) == y).sum().item()\n",
    "            total_count += y.size(0)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            t.set_postfix({'loss': total_loss/total_count, 'acc': total_acc/total_count})\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with tqdm.tqdm(valid_loader) as t:\n",
    "        for x, y in t:\n",
    "            logits = model(x)\n",
    "            total_acc += (logits.argmax(1) == y).sum().item()\n",
    "            total_count += len(y)\n",
    "            y_pred += logits.argmax(1).tolist()\n",
    "            y_true += y.tolist()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\n\\n\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2ac09f9f71c077dcb1c7223c167cd59df7105082dea9d9c96e1594093039292"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('comp4471')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
